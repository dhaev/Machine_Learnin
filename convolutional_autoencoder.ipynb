{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhaev/Machine-Learning/blob/main/CNN_Autoencoders.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57c21f82-7c9b-45e3-9426-eeb491f73246"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import zipfile\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import os\n",
        "\n",
        "import concurrent.futures\n",
        "import multiprocessing"
      ],
      "id": "57c21f82-7c9b-45e3-9426-eeb491f73246"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rtMne1QP0Ju",
        "outputId": "41563b04-e2d8-4319-fc1c-d1b9e61eeabe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "3rtMne1QP0Ju"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ad6d118-f392-42af-a5ce-562fe87cc1dc"
      },
      "outputs": [],
      "source": [
        "# @title Your Title Here\n",
        "\n",
        "class CustomDataset():\n",
        "    def __init__(self, x=None, y=None, img_size=(224, 224)):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        self.img_size = img_size\n",
        "\n",
        "    @staticmethod\n",
        "    def process_image(filename):\n",
        "        try:\n",
        "            image = tf.io.read_file(filename)\n",
        "            if filename.lower().endswith('.jpeg') or filename.lower().endswith('.jpg'):\n",
        "                image = tf.image.decode_jpeg(image, channels=3)\n",
        "            elif filename.lower().endswith('.png'):\n",
        "                image = tf.image.decode_png(image, channels=3)\n",
        "            else:\n",
        "                image = tf.image.decode_image(image, channels=3)\n",
        "            image = tf.image.resize(image, [224, 224])\n",
        "            image /= 255.0  # normalize to [0,1] range\n",
        "\n",
        "            # If the image does not have three dimensions, return None\n",
        "            if len(image.shape) != 3:\n",
        "                return None\n",
        "            return image\n",
        "        except Exception as e:\n",
        "            # print(f\"Error: {e}, with image path: {filename}. Skipping.\")\n",
        "            return None\n",
        "\n",
        "    @classmethod\n",
        "    def get_batch_images(cls, batch_x, batch_y):\n",
        "        batch_images = []\n",
        "        batch_labels = []\n",
        "        with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "            images = list(executor.map(cls.process_image, batch_x))\n",
        "        for image, label in zip(images, batch_y):\n",
        "            if image is not None:\n",
        "                batch_images.append(image)\n",
        "                batch_labels.append(label)\n",
        "        batch_images = tf.stack(batch_images)\n",
        "        batch_labels = tf.one_hot(batch_labels, depth=2)\n",
        "        return batch_images, batch_images"
      ],
      "id": "9ad6d118-f392-42af-a5ce-562fe87cc1dc"
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "\n",
        "In this modified version, Iâ€™ve moved the sampling of indices to a separate method sample_indices for better readability.\n",
        "The half_batch_size is now computed only once, and list comprehension is used to create sampled_indices_list.\n",
        "These changes should makes the code faster and more efficient\n",
        "'''\n",
        "class BatchData():\n",
        "    def __init__(self, data=None, batch_size=64):\n",
        "        if not isinstance(data, pd.DataFrame):\n",
        "            raise TypeError(\"data must be a pandas DataFrame\")\n",
        "        if not isinstance(batch_size, int) or batch_size <= 0:\n",
        "            raise ValueError(\"batch_size must be a positive integer\")\n",
        "        self.data = data\n",
        "        self.labels = self.data['labels'].unique()\n",
        "        self.dfs = {label: self.data[self.data['labels'] == label] for label in self.labels}\n",
        "        self.indices = {label: np.arange(len(df)) for label, df in self.dfs.items()}\n",
        "        self.batch_size = batch_size\n",
        "        self.batches = []\n",
        "\n",
        "    def batch(self, max_iterations=2000):\n",
        "        if not isinstance(max_iterations, int) or max_iterations <= 0:\n",
        "            raise ValueError(\"max_iterations must be a positive integer\")\n",
        "        iterations = 0\n",
        "        half_batch_size = int(self.batch_size / 2)\n",
        "        while all(len(indices) > 0 for indices in self.indices.values()) and iterations < max_iterations:\n",
        "            sampled_indices_list = [\n",
        "                self.sample_indices(label, half_batch_size)\n",
        "                for label in self.labels\n",
        "            ]\n",
        "            self.batches.append(sampled_indices_list)\n",
        "            iterations += 1\n",
        "\n",
        "    def sample_indices(self, label, half_batch_size):\n",
        "        if len(self.indices[label]) < half_batch_size:\n",
        "            sampled_indices = np.random.choice(self.indices[label], size=half_batch_size, replace=True)\n",
        "        else:\n",
        "            sampled_indices = np.random.choice(self.indices[label], size=half_batch_size, replace=False)\n",
        "        self.indices[label] = np.setdiff1d(self.indices[label], sampled_indices)\n",
        "        return (label, sampled_indices)\n",
        "\n",
        "    def generator(self):\n",
        "        while True:\n",
        "            for batch in self.batches:\n",
        "                sampled_dfs = [\n",
        "                    self.dfs[label].iloc[indices]\n",
        "                    for label, indices in batch\n",
        "                ]\n",
        "                sampled_df = pd.concat(sampled_dfs).sample(frac=1).reset_index(drop=True)\n",
        "                batch_x = sampled_df.iloc[:, 0]  # All rows and the first column\n",
        "                batch_y = sampled_df.iloc[:, -1]  # All rows and the last column\n",
        "                batch_images, batch_labels = CustomDataset.get_batch_images(batch_x, batch_y)\n",
        "                yield batch_images, batch_labels\n"
      ],
      "metadata": {
        "id": "KlSvhhyOUt_C"
      },
      "id": "KlSvhhyOUt_C",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lV4E-MdERSGr"
      },
      "outputs": [],
      "source": [
        "\n",
        "def zip_extract(file_name):\n",
        "    # Open the zip file in read mode\n",
        "    with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
        "        # Extract all files in the zip file\n",
        "        zip_ref.extractall()\n",
        "\n",
        "# List of zip files to extract\n",
        "zip_files = [\n",
        "    # \"/content/drive/MyDrive/Machine Learning/datasets/cats_and_dogs.zip\",\n",
        "             \"/content/drive/MyDrive/Machine Learning/datasets/Cats-vs-Dogs.zip\"\n",
        "             ]\n",
        "\n",
        "# # Create a pool of workers\n",
        "# with multiprocessing.Pool() as pool:\n",
        "#     # Use the pool to run zip_extract concurrently on all zip files\n",
        "#     pool.map(zip_extract, zip_files)\n",
        "\n",
        "# Create a ThreadPoolExecutor\n",
        "with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "    # Use the executor to run zip_extract concurrently on all zip files\n",
        "    executor.map(zip_extract, zip_files)"
      ],
      "id": "lV4E-MdERSGr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cZsTCQG3CfCj"
      },
      "outputs": [],
      "source": [
        "\n",
        "def balance_dataframe(df, label_column='labels', n_samples=1600):\n",
        "    # Get the unique labels\n",
        "    labels = df[label_column].unique()\n",
        "\n",
        "    # Create an empty DataFrame to store the balanced data\n",
        "    balanced_df = pd.DataFrame()\n",
        "\n",
        "    for label in labels:\n",
        "        # Get a subset of the DataFrame with the current label\n",
        "        subset = df[df[label_column] == label]\n",
        "\n",
        "        # If the subset is larger than n_samples, randomly select n_samples rows\n",
        "        if len(subset) > n_samples:\n",
        "            subset = subset.sample(n_samples)\n",
        "        # If the subset is smaller than n_samples, oversample it to reach n_samples\n",
        "        elif len(subset) < n_samples:\n",
        "            subset = subset.sample(n_samples, replace=True)\n",
        "\n",
        "        # Append the subset to the balanced DataFrame\n",
        "        balanced_df = pd.concat([balanced_df, subset])\n",
        "\n",
        "    return balanced_df"
      ],
      "id": "cZsTCQG3CfCj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3b388120-54d2-4f6c-9965-202c68b096cb"
      },
      "outputs": [],
      "source": [
        "def load_images(folder_name):\n",
        "    try:\n",
        "        folder_path = os.path.join(base_folder_path, folder_name)\n",
        "        image_path = [f\"{folder_path}/{x}\" for x in os.listdir(folder_path)]\n",
        "        label_dict = {'Cat': 0, 'Dog': 1}\n",
        "        # label_dict = {'cat': 0, 'dog': 1}\n",
        "        image_label = [label_dict[folder_name]] * len(image_path)\n",
        "        return image_path, image_label\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}, with folder: {folder_name}. Skipping.\")\n",
        "        return [], []\n",
        "\n",
        "base_folder_path = '/content/Cats-vs-Dogs/PetImages'\n",
        "# base_folder_path = '/content/drive/MyDrive/Machine Learning/datasets/Cats-vs-Dogs/PetImages'\n",
        "# base_folder_path = '/content/drive/MyDrive/Machine Learning/datasets/cats_and_dogs/train'\n",
        "pet_dict = {'images': [], 'labels': []}\n",
        "\n",
        "try:\n",
        "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
        "        results = list(executor.map(load_images, os.listdir(base_folder_path)))\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}. Failed to load images.\")\n",
        "\n",
        "for result in results:\n",
        "    pet_dict['images'].extend(result[0])\n",
        "    pet_dict['labels'].extend(result[1])\n",
        "pet_df = pd.DataFrame(pet_dict)\n",
        "# pet_df.to_csv(\"/content/drive/MyDrive/Machine Learning/datasets/cats_and_dogs/train/cats_and_dogs_train.csv\",index=False)"
      ],
      "id": "3b388120-54d2-4f6c-9965-202c68b096cb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OUmLK16ixxgh"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/content/Cats-vs-Dogs/PetImages/Cat\" \"/content/drive/MyDrive/Machine Learning/Cats-vs-Dogs/PetImages/\""
      ],
      "id": "OUmLK16ixxgh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "24Il44URFJB8"
      },
      "outputs": [],
      "source": [
        "# Shuffle the data\n",
        "pet_df = pet_df.sample(frac=1, random_state=42)\n",
        "\n",
        "# Define sizes\n",
        "train_size = int(0.7 * len(pet_df))\n",
        "val_size = int(0.15 * len(pet_df))\n",
        "test_size = int(0.15 * len(pet_df))\n",
        "\n",
        "# Split the data\n",
        "train_dataset = pet_df[:train_size]\n",
        "val_dataset = pet_df[train_size:train_size+val_size]\n",
        "test_data = pet_df[train_size+val_size:]"
      ],
      "id": "24Il44URFJB8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c52f9d2b-9b99-4f2e-9eee-e16558272be2",
        "outputId": "2aa8f90d-148a-4fbd-d572-33f8dd0ec954"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "\n",
        "batch_data_instance = BatchData(data=train_dataset, batch_size=32)\n",
        "\n",
        "batch_data_instance.batch()\n",
        "set(pet_df['labels'].values)"
      ],
      "id": "c52f9d2b-9b99-4f2e-9eee-e16558272be2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8f2461c7-b235-421f-a221-3d14dfb6eac3"
      },
      "outputs": [],
      "source": [
        "val_features, val_labels = CustomDataset.get_batch_images(val_dataset['images'], val_dataset['labels'])"
      ],
      "id": "8f2461c7-b235-421f-a221-3d14dfb6eac3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6XXD1BjjRrV",
        "outputId": "632f9933-d3f3-4b44-bb50-6b053e052d76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0, 1}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "set(val_dataset['labels'].values)"
      ],
      "id": "S6XXD1BjjRrV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04815814-b00b-404a-a644-661553c5e561"
      },
      "outputs": [],
      "source": [
        "from keras import layers\n",
        "\n",
        "input_img = keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "encoded = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
        "\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "x = layers.Conv2D(16, (3, 3), activation='relu', padding='same')(x)  # change this line\n",
        "x = layers.UpSampling2D((2, 2))(x)\n",
        "decoded = layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "autoencoder = keras.Model(input_img, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n"
      ],
      "id": "04815814-b00b-404a-a644-661553c5e561"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1ZqtVdQ3ycR",
        "outputId": "348a869f-7d54-497c-842e-88cbd58e33cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "steps_per_epoch = 546\n"
          ]
        }
      ],
      "source": [
        "epoch = 15\n",
        "# Get the number of steps per epoch\n",
        "steps_per_epoch = len(batch_data_instance.batches)\n",
        "print(f\"steps_per_epoch = {steps_per_epoch}\")"
      ],
      "id": "O1ZqtVdQ3ycR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HDhovnopOZvn",
        "outputId": "0865e095-9774-4717-c728-75152cd1f3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "546/546 [==============================] - 88s 148ms/step - loss: 0.5660 - val_loss: 0.5514\n",
            "Epoch 2/20\n",
            "546/546 [==============================] - 76s 138ms/step - loss: 0.5509 - val_loss: 0.5472\n",
            "Epoch 3/20\n",
            "546/546 [==============================] - 76s 140ms/step - loss: 0.5490 - val_loss: 0.5462\n",
            "Epoch 4/20\n",
            "546/546 [==============================] - 71s 130ms/step - loss: 0.5481 - val_loss: 0.5452\n",
            "Epoch 5/20\n",
            "546/546 [==============================] - 73s 134ms/step - loss: 0.5472 - val_loss: 0.5442\n",
            "Epoch 6/20\n",
            "546/546 [==============================] - 71s 130ms/step - loss: 0.5464 - val_loss: 0.5437\n",
            "Epoch 7/20\n",
            "546/546 [==============================] - 75s 137ms/step - loss: 0.5459 - val_loss: 0.5432\n",
            "Epoch 8/20\n",
            "546/546 [==============================] - 77s 141ms/step - loss: 0.5455 - val_loss: 0.5440\n",
            "Epoch 9/20\n",
            "546/546 [==============================] - 68s 125ms/step - loss: 0.5454 - val_loss: 0.5432\n",
            "Epoch 10/20\n",
            "546/546 [==============================] - 74s 136ms/step - loss: 0.5452 - val_loss: 0.5439\n",
            "Epoch 11/20\n",
            "279/546 [==============>...............] - ETA: 32s - loss: 0.5454"
          ]
        }
      ],
      "source": [
        "aut  = autoencoder.fit(batch_data_instance.generator(), steps_per_epoch=steps_per_epoch, epochs=20, validation_data=(val_features,val_features))"
      ],
      "id": "HDhovnopOZvn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdwJWgG11zZM"
      },
      "outputs": [],
      "source": [
        "def plot_history(hist):\n",
        "  # acc = hist.history['accuracy']\n",
        "  # val_acc = hist.history['val_accuracy']\n",
        "\n",
        "  loss = hist.history['loss']\n",
        "  val_loss = hist.history['val_loss']\n",
        "\n",
        "  epochs_range = range(epoch)\n",
        "\n",
        "  plt.figure(figsize=(8, 8))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  # plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "  # plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "  # plt.legend(loc='lower right')\n",
        "  # plt.title('Training and Validation Accuracy')\n",
        "\n",
        "  plt.subplot(1, 2, 2)\n",
        "  plt.plot(epochs_range, loss, label='Training Loss')\n",
        "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "  plt.legend(loc='upper right')\n",
        "  plt.title('Training and Validation Loss')\n",
        "  plt.show()"
      ],
      "id": "FdwJWgG11zZM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-XUWTL9f26gN"
      },
      "outputs": [],
      "source": [
        "plot_history(aut)"
      ],
      "id": "-XUWTL9f26gN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "REjhv-pMlLX_"
      },
      "outputs": [],
      "source": [
        "# hist_df = pd.DataFrame(history.history)"
      ],
      "id": "REjhv-pMlLX_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVrceS0JlM04"
      },
      "outputs": [],
      "source": [
        "# with open('/content/drive/MyDrive/Machine Learning/cnn/History/model1', mode='w') as f:\n",
        "#     hist_df.to_csv(f, index=False)"
      ],
      "id": "xVrceS0JlM04"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLm9QjaqlzOn"
      },
      "outputs": [],
      "source": [
        "# rd=pd.read_csv('/content/drive/MyDrive/Machine Learning/cnn/History/model1')\n",
        "# rd"
      ],
      "id": "RLm9QjaqlzOn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPA6dyq8mv2l"
      },
      "outputs": [],
      "source": [
        "# # Assuming 'model' is your Keras model\n",
        "# with open('/content/drive/MyDrive/Machine Learning/cnn/History/model1_summary.txt', 'w') as f:\n",
        "#     # Pass the file handle in as a lambda function to 'print_fn' for the summary method\n",
        "#     model.summary(print_fn=lambda x: f.write(x + '\\n'))\n"
      ],
      "id": "RPA6dyq8mv2l"
    },
    {
      "cell_type": "code",
      "source": [
        "decoded_imgs = autoencoder.predict(val_features)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(1, n + 1):\n",
        "    # Display original\n",
        "    ax = plt.subplot(2, n, i)\n",
        "    plt.imshow(x_test[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    # Display reconstruction\n",
        "    ax = plt.subplot(2, n, i + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VYuWJakxdCth"
      },
      "id": "VYuWJakxdCth",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "594HLL92NG6J"
      },
      "id": "594HLL92NG6J"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n6u6r29kNFx2"
      },
      "id": "n6u6r29kNFx2",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
